{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Iir7RZNyT7R"
   },
   "source": [
    "# <font color='red'>**Loading cycleGan components**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11463,
     "status": "ok",
     "timestamp": 1638402571911,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "_tZG63Rl0yMM",
    "outputId": "b21f5230-1c75-42bb-9e36-a1eac60caa2c"
   },
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2655,
     "status": "ok",
     "timestamp": 1638402574556,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "YC5rYpL_yXtl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import glob\n",
    "#For embedding classification\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import csv\n",
    "import imageio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x38UCEwJ08m6"
   },
   "source": [
    "**import and reuse pix2pix models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4243,
     "status": "ok",
     "timestamp": 1638403803858,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "jPQ72XLG1BCg"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feQZiCXQ1EWo"
   },
   "source": [
    "**Optimizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1638403803860,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "Faeu3MD21D3U"
   },
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20338,
     "status": "ok",
     "timestamp": 1638403824186,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "rx4kEoQdzrsv",
    "outputId": "ab61e6a9-12ad-4e49-9ce6-594bdc2093ec"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"../models/rgb/\"\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RadcYqef2KSH"
   },
   "source": [
    "**Loading model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1638403824187,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "tnMBVuvd13Mm",
    "outputId": "8b3c95da-4d68-4a6d-bb83-08b74ef163f0"
   },
   "outputs": [],
   "source": [
    "generator_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only for net understanding\n",
    "#print(discriminator_x.get_layer('conv2d_20').layers[0].get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "executionInfo": {
     "elapsed": 1464,
     "status": "ok",
     "timestamp": 1638403825630,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "L1RpuC8b1-SA",
    "outputId": "de9b58b2-c163-4224-df8f-7ccf500c2e22"
   },
   "outputs": [],
   "source": [
    "plot_model(discriminator_x, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piIiP_jS2Pqm"
   },
   "source": [
    "<font color='red'>**Getting submodel for embedding space**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in generator_g.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1638403825634,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "dfgDJz_t2I7H"
   },
   "outputs": [],
   "source": [
    "l1 = generator_g.get_layer(name='concatenate')\n",
    "emb = Model(generator_g.input, l1.output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1638403825635,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "Q6PeQyVy38sY",
    "outputId": "28b3a1bf-f8d1-47a7-c4da-611ddb823c22"
   },
   "outputs": [],
   "source": [
    "emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1638403826269,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "9xWr1qW_CrX0",
    "outputId": "3f9e31a3-fbf0-4544-ed8b-09bdc5946b29"
   },
   "outputs": [],
   "source": [
    "plot_model(emb, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tELNGO-Z8MgJ"
   },
   "source": [
    "**Resolviendo el problema con capa concatenate...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1638406103507,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "OHlxMNTW2P3P",
    "outputId": "a182c95f-ed69-4b96-9997-735cd33ddf90"
   },
   "outputs": [],
   "source": [
    "l1 = generator_g.get_layer(name='concatenate')\n",
    "emb = Model(generator_g.input, l1.output)\n",
    "\n",
    "#for solve problem\n",
    "#inputs = keras.Input(shape=(295, 2, 2, 1024), name='img')\n",
    "input = emb.output\n",
    "x = Conv2D(filters=dim, kernel_size=(2,2))(input)\n",
    "x = layers.Reshape((dim,))(x)\n",
    "emb2 = Model(inputs=emb.input, outputs=x)\n",
    "emb2.summary()\n",
    "\n",
    "#from this it works:\n",
    "#x = layers.Reshape((4096,))(input)\n",
    "#emb2 = Model(inputs = emb.input, outputs = x)\n",
    "#emb2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Help functions**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(train_df):\n",
    "    \n",
    "    #datagenerator using 25% for validation\n",
    "    datagen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "    train_generator= datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                x_col=\"path\",\n",
    "                                                y_col=\"label\",\n",
    "                                                subset=\"training\",\n",
    "                                                batch_size=32,\n",
    "                                                seed=42,\n",
    "                                                shuffle=True,\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                #color_mode=\"grayscale\",\n",
    "                                                target_size=(256, 256))\n",
    "    \n",
    "    return train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_testing_dataframe(test_df):\n",
    "    test_df = test_df.sort_values(by='path')\n",
    "    test_df['Frame'] = (\n",
    "         test_df.apply(lambda x: int(x.path.split('/')[-1].split('_')[-1][:-4]), axis=1)\n",
    "         )\n",
    "    return test_df.sort_values(by='Frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(nomb_video, emb, classifier, test_df):\n",
    "    batch = len(test_df)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "    #Obtiene el número de frames.\n",
    "    number_of_frames = test_df.Frame\n",
    "    test_generator=test_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                                  x_col=\"path\",\n",
    "                                                  y_col=\"label\",\n",
    "                                                  batch_size=1,\n",
    "                                                  seed=42,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                  target_size=(256, 256))\n",
    "    \n",
    "    print(\"cycleGan predicting over test set...\")\n",
    "    X_test = emb.predict(test_generator, steps = batch, verbose=1)\n",
    "    can = X_test.shape[0]\n",
    "    label = nomb_video.split('_')[0]\n",
    "    Y_test = [label]*can\n",
    "    print(\"***TEST***amount of ade:{}, hyp:{}, ser:{}\".format(Y_test.count(\"adenoma\"),\n",
    "                                                              Y_test.count(\"hiperplastic\"),\n",
    "                                                              Y_test.count(\"serrated\")))\n",
    "    \n",
    "    \n",
    "    print(\"classifier over test set...\")\n",
    "    preds = classifier.predict(X_test)\n",
    "    for k in range(len(preds)):\n",
    "        pred_k = preds[k]\n",
    "        real_k = Y_test[k]\n",
    "        writer.writerow([nomb_video, number_of_frames.iloc[k], pred_k, real_k])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZngWGgry8Szy"
   },
   "source": [
    "# <font color='red'>**CycleGan predicting and embedding classification**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyps = {0: \"adenoma\",\n",
    "         1: \"hiperplastic\",\n",
    "         2: \"serrated\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main\n",
    "Downsampling approach\n",
    "1. Original csv frames reading into a dataframe\n",
    "2. Dataframe sorting\n",
    "3. For each video (LOPO), get from the \"minimo\" variable value taking his 25% left, 25% right from the center value of each frame\n",
    "4. For the previous frames get embedding space from cycleGan net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimo = 9999\n",
    "gen_path = '../../../../pregrado/data/RGB/NBI/'\n",
    "clases = os.listdir(gen_path)\n",
    "for clase in clases:\n",
    "    videos_path = gen_path + clase    \n",
    "    videos = os.listdir(videos_path)\n",
    "    for video in videos:\n",
    "        imgs_path = videos_path + '/' + video\n",
    "        can = len(os.listdir(imgs_path))\n",
    "        if can < minimo:\n",
    "            minimo = can\n",
    "            tipo = clase\n",
    "            num_vid = video\n",
    "print(\"la clase con menor cantidad de frames es: {}, en el video: {}, con {} frames\".format(tipo, num_vid, minimo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../../../pregrado/data/realWL.csv'\n",
    "train_df = pd.read_csv(data_path, header=None)\n",
    "train_df.columns = [\"path\", \"label\"]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downsamplig data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"adenoma:0\n",
    "hyperplastic:1\n",
    "serrated:2\n",
    "\"\"\"\n",
    "csvfile = open('downsampledRGBorigData.csv', '+w')\n",
    "clases = [\"adenoma_NBI/\", \"hiperplastic_NBI/\", \"serrated_NBI/\"]\n",
    "for clase in clases:\n",
    "    \n",
    "    print(\"==== working on \", clase, \"====\")\n",
    "    if clase == \"adenoma_NBI/\":\n",
    "        cant = 40\n",
    "        target = ',adenoma\\n'\n",
    "    elif clase == \"hiperplastic_NBI/\":\n",
    "        cant = 21\n",
    "        target = ',hiperplastic\\n'\n",
    "    else:\n",
    "        cant = 15\n",
    "        target = ',serrated\\n'\n",
    "    \n",
    "    for i in range(1, cant+1):\n",
    "        print(\"================================= video #\", i,\"===========================================\")  \n",
    "        current_test_df = train_df[train_df['path'].str.contains(clase+'video_'+str(i)+'/')]\n",
    "        current_test_df = current_test_df.reset_index(drop=True)\n",
    "        #sort actual video frames\n",
    "        current_test_df = sort_testing_dataframe(current_test_df)\n",
    "        current_test_df = current_test_df.reset_index(drop=True)\n",
    "        can_frames = len(current_test_df)\n",
    "        #getting frames from the middle of video\n",
    "        samples = int(minimo/2)\n",
    "        idx = int(can_frames/2)\n",
    "        tmp_df = current_test_df.loc[idx-samples:idx+samples]\n",
    "        tmp_df = tmp_df.reset_index(drop=True)\n",
    "        #go throught temp data frame\n",
    "        for j in range(len(tmp_df)):\n",
    "            path = tmp_df['path'][j]\n",
    "            csvfile.write(path+target)\n",
    "            \n",
    "csvfile.close()\n",
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downsampled data verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csv = '../data/rgb/csvFiles/downsampledRGBorigData.csv'\n",
    "new_train_df = pd.read_csv(new_csv, header=None)\n",
    "new_train_df.columns = ['path', 'label']\n",
    "new_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave one out \n",
    "### Getting embedding space over downsampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**saving embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_emb(clase, embeddings, labels, videos, dim_folder):\n",
    "    embeddings_arr = np.array(embeddings)\n",
    "    labels_arr = np.array(labels)\n",
    "    videos_arr = np.array(videos)\n",
    "    print(\"emb dimension: \", embeddings_arr.shape)\n",
    "    print(\"label dimension: \", labels_arr.shape)\n",
    "    print(\"videos dimension: \", videos_arr.shape)\n",
    "    file_name = \"../data/embeddings/GenA/correct_inputs/\"+dim_folder+'/'+clase\n",
    "    np.save(file_name+\"Embeddings\", embeddings_arr)\n",
    "    np.save(file_name+\"Labels\", labels_arr)\n",
    "    np.save(file_name+\"Videos\", videos_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**getting embedding space for all frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_folder = 'dim512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"adenoma:0\n",
    "hyperplastic:1\n",
    "serrated:2\n",
    "\"\"\"\n",
    "embeddings, labels, videos = [], [], [] \n",
    "#target_names = ['adenoma', 'hyperplastic', 'serrated']\n",
    "clase = \"adenoma_WL/\"\n",
    "cant = 40\n",
    "#with open('predict-embeddingAdenoma.csv', 'w', newline='') as file:\n",
    "    #writer = csv.writer(file)\n",
    "print(\"==== testing with \", clase, \"====\")\n",
    "for i in range(1, cant+1):\n",
    "    print(\"=================================kfold #\", i,\"===========================================\")  \n",
    "    current_test_df = train_df[train_df['path'].str.contains(clase+'video_'+str(i)+'/')]\n",
    "    current_test_df = current_test_df.reset_index(drop=True)\n",
    "    #sort test frames\n",
    "    current_test_df = sort_testing_dataframe(current_test_df)\n",
    "    #training data    \n",
    "    current_train_df = train_df[~train_df[\"path\"].str.contains(clase+'video_'+str(i)+'/')]\n",
    "    current_train_df = current_train_df.reset_index(drop=True)               \n",
    "    #make the train generator\n",
    "    x_test_gen = create_generator(current_test_df) \n",
    "\n",
    "    print(\"cycleGan predicting over test set...\")\n",
    "    X_train = emb2.predict(x_test_gen, verbose=1)\n",
    "    can = X_train.shape[0] \n",
    "    label = 'adenoma'\n",
    "    Y_train = [label]*can\n",
    "    video = \"video_\" + str(i)\n",
    "    W_train = [video]*can\n",
    "    #Y_train = [polyps[label] for label in x_train_gen.labels]\n",
    "    print(\"***TRAIN***: amount of ade:{}, hyp:{}, ser:{}\".format(Y_train.count(\"adenoma\"),\n",
    "                                                                 Y_train.count(\"hiperplastic\"),\n",
    "                                                                 Y_train.count(\"serrated\")))\n",
    "    embeddings.extend(X_train)\n",
    "    labels.extend(Y_train)\n",
    "    videos.extend(W_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "saving_emb(\"Adenoma\", embeddings, labels, videos, dim_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, labels, videos = [], [], []\n",
    "clase = \"hiperplastic_WL/\"\n",
    "cant = 21\n",
    "#with open('predict-embeddingHiperplastic.csv', 'w', newline='') as file:\n",
    "    #writer = csv.writer(file)\n",
    "print(\"==== testing with \", clase, \"====\")\n",
    "for i in range(1, cant+1):\n",
    "    print(\"=================================kfold #\", i+40,\"===========================================\")  \n",
    "    current_test_df = train_df[train_df['path'].str.contains(clase+'video_'+str(i)+'/')]\n",
    "    current_test_df = current_test_df.reset_index(drop=True)\n",
    "    #sort test frames\n",
    "    current_test_df = sort_testing_dataframe(current_test_df)\n",
    "    #training data    \n",
    "    current_train_df = train_df[~train_df[\"path\"].str.contains(clase+'video_'+str(i)+'/')]\n",
    "    current_train_df = current_train_df.reset_index(drop=True)\n",
    "\n",
    "    #make the train generator\n",
    "    x_train_gen = create_generator(current_test_df)        \n",
    "    print(\"cycleGan predicting over train set...\")\n",
    "    X_train = emb2.predict(x_train_gen, verbose=1)\n",
    "    can = X_train.shape[0] \n",
    "    label = 'hiperplastic'\n",
    "    Y_train = [label]*can\n",
    "    video = \"video_\" + str(i+40)\n",
    "    W_train = [video]*can\n",
    "\n",
    "    print(\"***TRAIN***: amount of ade:{}, hyp:{}, ser:{}\".format(Y_train.count(\"adenoma\"),\n",
    "                                                                 Y_train.count(\"hiperplastic\"),\n",
    "                                                                 Y_train.count(\"serrated\")))\n",
    "    embeddings.extend(X_train)\n",
    "    labels.extend(Y_train)\n",
    "    videos.extend(W_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "saving_emb(\"Hiperplastic\", embeddings, labels, videos, dim_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, labels, videos = [], [], []\n",
    "clase = \"serrated_WL/\"\n",
    "cant = 15\n",
    "#with open('predict-embeddingSerrated.csv', 'w', newline='') as file:\n",
    "    #writer = csv.writer(file)\n",
    "print(\"==== testing with \", clase, \"====\")\n",
    "for i in range(1, cant+1):\n",
    "    print(\"=================================kfold #\", i+61,\"===========================================\")  \n",
    "    current_test_df = train_df[train_df['path'].str.contains(clase+'video_'+str(i)+'/')]\n",
    "    current_test_df = current_test_df.reset_index(drop=True)\n",
    "    #sort test frames\n",
    "    current_test_df = sort_testing_dataframe(current_test_df)\n",
    "    #training data    \n",
    "    current_train_df = train_df[~train_df[\"path\"].str.contains(clase+'video_'+str(i)+'/')]\n",
    "    current_train_df = current_train_df.reset_index(drop=True)\n",
    "   #make the train generator\n",
    "    x_train_gen = create_generator(current_test_df)  \n",
    "\n",
    "    print(\"cycleGan predicting over train set...\")\n",
    "    X_train = emb2.predict(x_train_gen, verbose=1)\n",
    "    can = X_train.shape[0] \n",
    "    label = 'serrated'\n",
    "    Y_train = [label]*can\n",
    "    video = \"video_\" + str(i+61)\n",
    "    W_train = [video]*can\n",
    "\n",
    "    print(\"***TRAIN***: amount of ade:{}, hyp:{}, ser:{}\".format(Y_train.count(\"adenoma\"),\n",
    "                                                                 Y_train.count(\"hiperplastic\"),\n",
    "                                                                 Y_train.count(\"serrated\")))\n",
    "    embeddings.extend(X_train)\n",
    "    labels.extend(Y_train)\n",
    "    videos.extend(W_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "saving_emb(\"Serrated\", embeddings, labels, videos, dim_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical train/test split (80-20)\n",
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for adenoma general example: hiperplastic_NBI/video_3\n",
    "ade, hyp, ser = [], [], []\n",
    "for i in range(1,41):\n",
    "    text = \"adenoma_NBI/video_\" + str(i)\n",
    "    ade.append(text)\n",
    "    if i < 16:\n",
    "        text = \"hiperplastic_NBI/video_\" + str(i)        \n",
    "        hyp.append(text)\n",
    "        text = \"serrated_NBI/video_\" + str(i)\n",
    "        ser.append(text)\n",
    "    if i > 15 and i < 22:\n",
    "        text = \"hiperplastic_NBI/video_\" + str(i)\n",
    "        hyp.append(text)\n",
    "    \n",
    "print(\"ade videos:\\n\")\n",
    "print(ade)\n",
    "print(\"=================\")\n",
    "print(\"hyp videos:\\n\")\n",
    "print(hyp)\n",
    "print(\"=================\")\n",
    "print(\"ser videos:\\n\")\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ade_train, ade_test = train_test_split(ade, test_size=0.2, random_state=14)\n",
    "hyp_train, hyp_test = train_test_split(hyp, test_size=0.2, random_state=14)\n",
    "ser_train, ser_test = train_test_split(ser, test_size=0.2, random_state=14)\n",
    "\n",
    "print(\"ade videos train:\\n\")\n",
    "print(ade_train)\n",
    "print(\"ade videos test:\\n\")\n",
    "print(ade_test)\n",
    "print(\"=================\")\n",
    "print(\"hyp videos train:\\n\")\n",
    "print(hyp_train)\n",
    "print(\"hyp videos test:\\n\")\n",
    "print(hyp_test)\n",
    "print(\"=================\")\n",
    "print(\"ser videos train: \\n\")\n",
    "print(ser_train)\n",
    "print(\"ser videos test: \\n\")\n",
    "print(ser_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ade_train.extend(hyp_train)\n",
    "ade_train.extend(ser_train)\n",
    "train_set = ade_train\n",
    "random.shuffle(train_set)\n",
    "\n",
    "ade_test.extend(hyp_test)\n",
    "ade_test.extend(ser_test)\n",
    "test_set = ade_test\n",
    "random.shuffle(test_set)\n",
    "\n",
    "print(\"====== train amount: \", len(train_set),\" ======\")\n",
    "print(train_set)\n",
    "print(\"====== test amount: \", len(test_set),\" ======\")\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../../../pregrado/data/realNBI.csv'\n",
    "data_df = pd.read_csv(data_path, header=None)\n",
    "data_df.columns = [\"path\", \"label\"]\n",
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for test data\n",
    "embeddings, labels = [], [] \n",
    "for data in train_set:\n",
    "    clase = data.split('/')[0]\n",
    "    clase = clase.split('_')[0]\n",
    "    current_df = data_df[data_df['path'].str.contains(data)]  \n",
    "    x_train_gen = create_generator(current_df)        \n",
    "    print(\"cycleGan predicting over train set...\")\n",
    "    X_train = emb2.predict(x_train_gen, verbose=1)\n",
    "    can = X_train.shape[0]\n",
    "    Y_train = [clase]*can\n",
    "    embeddings.extend(X_train)\n",
    "    labels.extend(Y_train)\n",
    "    print(\"amount of ade:{}, hyp:{}, ser:{}\".format(labels.count(\"adenoma\"), labels.count(\"hiperplastic\"),\n",
    "                                                    labels.count(\"serrated\")))\n",
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For save and load embeddings data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_arr = np.array(embeddings)\n",
    "labels_arr = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"emb dimension: \", embeddings_arr.shape)\n",
    "print(\"label dimension: \", labels_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"trainEmbeddings\", embeddings_arr)\n",
    "np.save(\"trainEmbeddingsLabels\", labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb = np.load('trainEmbeddings.npy')\n",
    "test_emb_lab = np.load('trainEmbeddingsLabels.npy')\n",
    "print(test_emb.shape)\n",
    "print(test_emb_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_emb.tolist()\n",
    "y = test_emb_lab.tolist()\n",
    "print(y.count(\"adenoma\"), y.count(\"hiperplastic\"), y.count(\"serrated\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**All embedding data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../../../../pregrado/data/RGB/WL/\"\n",
    "pathname = directory + \"/**/*.png\"\n",
    "files = glob.glob(pathname, recursive=True)\n",
    "\n",
    "img_height, img_width = 256, 256\n",
    "video = []\n",
    "imagen = []\n",
    "label = []\n",
    "pred = [] \n",
    "\n",
    "for path in tqdm(files):\n",
    "    info = path.split('/')[-1]\n",
    "    clase = info.split('_')[0]\n",
    "    vid = info.split('_')[3]\n",
    "    img_ext = info.split('_')[-1]\n",
    "    image = img_ext.split('.')[0]    \n",
    "\n",
    "    img = keras.preprocessing.image.load_img(path, target_size=(img_height, img_width))\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = img_array* 1./255.\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "    logits = emb2.predict(img_array, steps = 1)\n",
    "    pred.extend(logits)\n",
    "    video.append(vid)\n",
    "    imagen.append(image)\n",
    "\n",
    "    if clase == 'adenoma':\n",
    "        label.append('adenoma')\n",
    "    elif clase == 'hiperplastic':\n",
    "        label.append('hiperplastic')\n",
    "    else:\n",
    "        label.append('serrated')\n",
    "\n",
    "#haciendo dataframe\n",
    "df = pd.DataFrame(list(zip(video, imagen, label, pred)), columns=['#Video', '#imagen', 'clase', 'predicción'])\n",
    "\n",
    "#pred = np.squeeze(pred, axis=1)\n",
    "pred = np.array(pred)\n",
    "print(\"dimension of predic: \", pred.shape)\n",
    "\n",
    "#label = np.squeeze(label, axis=1)\n",
    "label = np.array(label)\n",
    "print(\"dimension of label: \", label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For save and load embeddings data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_arr = np.array(pred)\n",
    "labels_arr = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"emb dimension: \", embeddings_arr.shape)\n",
    "print(\"label dimension: \", labels_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"embeddings60\", embeddings_arr)\n",
    "np.save(\"embeddingsLabels60\", labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb = np.load('embeddings60.npy')\n",
    "test_emb_lab = np.load('embeddingsLabels60.npy')\n",
    "print(test_emb.shape)\n",
    "print(test_emb_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_emb.tolist()\n",
    "y = test_emb_lab.tolist()\n",
    "print(y.count(\"adenoma\"), y.count(\"hiperplastic\"), y.count(\"serrated\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzmA16Fzv9_e"
   },
   "source": [
    "# <font color='red'>**Dimension reduction**</font>\n",
    "## T-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1686,
     "status": "ok",
     "timestamp": 1638406163205,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "TyI9JqE0wOTf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from scipy.spatial.distance import pdist\n",
    "#from sklearn.manifold.t_sne import _joint_probabilities\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "palette = sns.color_palette(\"bright\", 10)\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2022,
     "status": "ok",
     "timestamp": 1638406167239,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "EErD91ZpwDou",
    "outputId": "6ccfc6bb-e1e7-4744-fd9f-eca30461c7ab"
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = 2, init = 'pca')\n",
    "P1_tsne = tsne.fit_transform(test_emb)\n",
    "P1_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1638406170023,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "K2CbSbBMwUFu"
   },
   "outputs": [],
   "source": [
    "l1 = P1_tsne[:,0]\n",
    "l2 = P1_tsne[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1638406172054,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "FEyRMxsIwbXX"
   },
   "outputs": [],
   "source": [
    "#df = df.drop(columns='predicción')\n",
    "df['x'] = l1\n",
    "df['y'] = l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1638406173207,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "RzCk1qDiwd-N"
   },
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df['clase'] == 'adenoma'),\n",
    "    (df['clase'] == 'hiperplastic'),\n",
    "    (df['clase'] == 'serrated')\n",
    "    ]\n",
    "\n",
    "values = [1, 2, 3]\n",
    "\n",
    "df['labels'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1638406174382,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "QjxGXPvzwkkg",
    "outputId": "90cf596a-fae9-4675-c9eb-f6f4cc436c27"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRtfiHmSxBog"
   },
   "source": [
    "### **Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1638407445966,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "yK1qANUCxALJ",
    "outputId": "3fd5459a-877a-44bb-a59e-b349e4bdaae6"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x=\"x\", y=\"y\", color = 'clase', hover_name=\"clase\", hover_data=[\"#Video\"], opacity=0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(test_features)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPqdeSIQ78WkFGSstZwtd+f",
   "mount_file_id": "1b4U_bJNhZS74sBCADJAb_se4Jfwt7DcX",
   "name": "cycleGanEmbedding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
