{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzPBhd4hSWKm"
   },
   "source": [
    "**TensorFlow tuto:** https://www.tensorflow.org/tutorials/generative/cyclegan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fkr7VTmL3XjB"
   },
   "source": [
    "# Main libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8252,
     "status": "ok",
     "timestamp": 1624550113244,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "gkUiPozb2qyf",
    "outputId": "9c0f6999-df80-4a9f-e382-3653fcd81cfe"
   },
   "outputs": [],
   "source": [
    "#allows to import generator and discriminator\n",
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDKg3BXM4oMd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlVDjmQs8UUP"
   },
   "source": [
    "# Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOxIM7sUvseF"
   },
   "source": [
    "**Needed the first time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-ozSD__6pc7"
   },
   "outputs": [],
   "source": [
    "# load all images in a directory into memory\n",
    "def load_images(path, size= (256,256), rgb= False):\n",
    "    \"\"\"Load images function for cycleGan train\n",
    "    \n",
    "    Parameters:\n",
    "    path: strin- where images are salved (tran and test for both domains: A and B white and NBI light)\n",
    "    size: array- image size\n",
    "    rgb: boolean- False for work with grayscale images\n",
    "    \"\"\"\n",
    "    data_list= list()\n",
    "    # enumerate filenames in directory, assume all are images\n",
    "    for filename in listdir(path):          \n",
    "        # load and resize the image\n",
    "        pixels= load_img(path + filename, target_size= size, color_mode= \"rgb\")\n",
    "        # convert to numpy array\n",
    "        pixels= img_to_array(pixels)\n",
    "        #new lines\n",
    "        if rgb==False:\n",
    "            img2= np.zeros((pixels.shape))\n",
    "            pixels= load_img(path + filename, target_size=size, color_mode= \"grayscale\")\n",
    "            img2[:,:,0]= pixels\n",
    "            img2[:,:,1]= pixels\n",
    "            img2[:,:,2]= pixels\n",
    "            # store\n",
    "            data_list.append(img2)\n",
    "        else:\n",
    "            # store\n",
    "            data_list.append(pixels)      \n",
    "    return asarray(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1957290,
     "status": "ok",
     "timestamp": 1623337285519,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "onwoXFlU7FER",
    "outputId": "dc084731-20c5-4814-cf5c-ea2477bdc78d"
   },
   "outputs": [],
   "source": [
    "\"\"\"Frames loading.\n",
    "Sets domains: A for white light and B for NBI\n",
    "rgb parameter sets as False for work whit grayscale images\n",
    "\"\"\"\n",
    "# dataset path\n",
    "path = '/home/franklin/Maestria/data/polyps/'\n",
    "# load dataset white light\n",
    "# here A: white light, B: nbi light\n",
    "train_WL = load_images(path + 'trainA/', rgb= True)\n",
    "test_WL = load_images(path + 'testA/', rgb= True)\n",
    "########dataA = vstack((dataA1, dataA2))\n",
    "########print('Loaded dataA: ', dataA.shape)\n",
    "# load dataset B\n",
    "train_NBI = load_images(path + 'trainB/', rgb= True)\n",
    "test_NBI = load_images(path + 'testB/', rgb= True)\n",
    "########dataB = vstack((dataB1, dataB2))\n",
    "########print('Loaded dataB: ', dataB.shape)\n",
    "# save as compressed numpy array\n",
    "#filename = '/content/drive/MyDrive/Maestria/Polyps/experiments/data/white2nbi_256.npz'\n",
    "#savez_compressed(filename, dataA, dataB)\n",
    "#print('Saved dataset: ', filename)\n",
    "print(\"train WL: \", train_WL.shape)\n",
    "print(\"train NBI: \", train_NBI.shape)\n",
    "print(\"test WL: \", test_WL.shape)\n",
    "print(\"testNBIL: \", test_NBI.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hyan-Q3Cv0H1"
   },
   "source": [
    "**Saving data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMpCcFE2jF9Z"
   },
   "outputs": [],
   "source": [
    "# save numpy array \n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "# save np\n",
    "np.save('trainA_rgb', train_WL)\n",
    "np.save('trainB_rgb', train_NBI)\n",
    "np.save('testA_rgb', test_WL)\n",
    "np.save('testB_rgb', test_NBI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74jS-ZCZpF8F"
   },
   "outputs": [],
   "source": [
    "test_NBI = np.load('../data/gray/testA_gray.npy')\n",
    "test_WL = np.load('../data/gray/testB_gray.npy')\n",
    "train_NBI = np.load('../data/gray/trainA_gray.npy')\n",
    "train_WL = np.load('../data/gray/trainB_gray.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7lhgM8-8Gcw"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W96k6Hxs801h"
   },
   "source": [
    "**Data augmentation techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_J-jiJ38nI2"
   },
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "    cropped_image = tf.image.random_crop(image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "    return cropped_image\n",
    "\n",
    "# scaling the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def random_jitter(image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    image = tf.image.resize(image, [286, 286], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aXhHl2z9CXX"
   },
   "source": [
    "**Preprocess splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-BB_9-b8xKf"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_train(image):\n",
    "    image = random_jitter(image)\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "def preprocess_image_test(image):\n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tAoNJ_nCeRW"
   },
   "outputs": [],
   "source": [
    "#conversion de las imageness a array\n",
    "train_WL_array = np.asarray(train_WL)\n",
    "test_WL_array = np.asarray(test_WL)\n",
    "train_NBI_array = np.asarray(train_NBI)\n",
    "test_NBI_array = np.asarray(test_NBI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7VErx21C5UX"
   },
   "outputs": [],
   "source": [
    "#Crea un dataSet de WL y NBI \n",
    "train_WL_ds = tf.data.Dataset.from_tensor_slices(train_WL_array)\n",
    "train_NBI_ds = tf.data.Dataset.from_tensor_slices(train_NBI_array)\n",
    "test_WL_ds = tf.data.Dataset.from_tensor_slices(test_WL_array)\n",
    "test_NBI_ds = tf.data.Dataset.from_tensor_slices(test_NBI_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-9xqJNY9KUL"
   },
   "outputs": [],
   "source": [
    "train_WL_ds = train_WL_ds.map(preprocess_image_train, \n",
    "                              num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "train_NBI_ds = train_NBI_ds.map(preprocess_image_train,\n",
    "                                num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_WL_ds = test_WL_ds.map(preprocess_image_test,\n",
    "                            num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_NBI_ds = test_NBI_ds.map(preprocess_image_test,\n",
    "                              num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogmBkVPI9WWI"
   },
   "outputs": [],
   "source": [
    "sample_WL = next(iter(train_WL_ds))\n",
    "sample_NBI = next(iter(train_NBI_ds))\n",
    "print(\"sample WL info:\")\n",
    "print(sample_WL.shape)\n",
    "print(\"sample NBI info:\")\n",
    "print(sample_NBI.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1624550230223,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "6xlFvqqhLqjf",
    "outputId": "5a127a7d-91df-4456-da7b-ae7c875bc317"
   },
   "outputs": [],
   "source": [
    "b = test_NBI_array[0]\n",
    "plt.hist(b.ravel())\n",
    "plt.title(\"Before scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1624550232521,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "-a64wkX694Sn",
    "outputId": "d241f56c-387c-4d01-aad8-511f77b06f64"
   },
   "outputs": [],
   "source": [
    "a = np.array(sample_NBI[0])\n",
    "plt.hist(a.ravel())\n",
    "plt.title(\"After scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1624550236229,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "iN2I1vcy9kK5",
    "outputId": "81e63a78-9c36-4241-da4b-5910ee1b1bf8"
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('White light')\n",
    "plt.imshow(sample_WL[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('White light with random jitter')\n",
    "plt.imshow(random_jitter(sample_WL[0]) * 0.5 + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1624550238910,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "D-HKAmMS9w7o",
    "outputId": "a9eda09c-b1a4-4805-b33c-e39fd8fdcf98"
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('NBI light')\n",
    "plt.imshow(sample_NBI[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('NBI light with random jitter')\n",
    "plt.imshow(random_jitter(sample_NBI[0]) * 0.5 + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LX3KegPtTQxP"
   },
   "source": [
    "# Import and reuse the Pix2Pix models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgQXeVCaTUvF"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "executionInfo": {
     "elapsed": 32068,
     "status": "ok",
     "timestamp": 1624550285613,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "eYSghJ-FTUxU",
    "outputId": "1e26baaa-0297-4397-baa1-d99617529fab"
   },
   "outputs": [],
   "source": [
    "to_NBI = generator_g(sample_WL)\n",
    "to_WL = generator_f(sample_NBI)\n",
    "plt.figure(figsize=(8, 8))\n",
    "contrast = 8\n",
    "\n",
    "imgs = [sample_WL, to_NBI, sample_NBI, to_WL]\n",
    "title = ['WL', 'To NBI', 'NBI', 'To WL']\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title(title[i])\n",
    "    if i % 2 == 0:\n",
    "        plt.imshow(imgs[i][0] * 0.5 + 0.5)\n",
    "    else:\n",
    "        plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1624550292957,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "y536wXtvVy2d",
    "outputId": "da3776b7-3164-45d6-9345-ee26b6672e41"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Is a real NBI?')\n",
    "plt.imshow(discriminator_y(sample_NBI)[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Is a real WL?')\n",
    "plt.imshow(discriminator_x(sample_WL)[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0ZICF6RVlaN"
   },
   "source": [
    "## **Loss functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9v-28iXVpPu"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 10\n",
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjWBOfbdVpUU"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real, generated):\n",
    "    \n",
    "    real_loss = loss_obj(tf.ones_like(real), real)\n",
    "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    \n",
    "    return total_disc_loss * 0.5\n",
    "\n",
    "def generator_loss(generated):\n",
    "    return loss_obj(tf.ones_like(generated), generated)\n",
    "\n",
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "\n",
    "    return LAMBDA * loss1\n",
    "\n",
    "def identity_loss(real_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmbs66oOWR4e"
   },
   "source": [
    "## **Initializing optimizers, generator and discriminators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_27PI0wWBEW"
   },
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "har0dLBMWkQW"
   },
   "source": [
    "## **Check points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13853,
     "status": "ok",
     "timestamp": 1624550348689,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "50jrnN4jWBHF",
    "outputId": "6189da19-a93e-428b-9701-1089ade70120"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"../models/gray/\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ave9_8XLXI4P"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zLF-P0OaBkv"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkKWjH_IXGxv"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input):\n",
    "    prediction = model(test_input)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PF6EGAqXeYu"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "    # persistent is set to True because the tape is used more than\n",
    "    # once to calculate the gradients.\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generator G translates X -> Y\n",
    "        # Generator F translates Y -> X.\n",
    "\n",
    "        fake_y = generator_g(real_x, training=True)\n",
    "        cycled_x = generator_f(fake_y, training=True)\n",
    "        #same for revert domain traslation\n",
    "        fake_x = generator_f(real_y, training=True)\n",
    "        cycled_y = generator_g(fake_x, training=True)\n",
    "\n",
    "        # same_x and same_y are used for identity loss.\n",
    "        same_x = generator_f(real_x, training=True)\n",
    "        same_y = generator_g(real_y, training=True)\n",
    "\n",
    "        disc_real_x = discriminator_x(real_x, training=True)\n",
    "        disc_real_y = discriminator_y(real_y, training=True)\n",
    "\n",
    "        disc_fake_x = discriminator_x(fake_x, training=True)\n",
    "        disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "        # calculate the loss\n",
    "        gen_g_loss = generator_loss(disc_fake_y)\n",
    "        gen_f_loss = generator_loss(disc_fake_x)\n",
    "\n",
    "        total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
    "\n",
    "        # Total generator loss = adversarial loss + cycle loss\n",
    "        total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "        total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
    "\n",
    "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "\n",
    "    # Calculate the gradients for generator and discriminator\n",
    "    generator_g_gradients = tape.gradient(total_gen_g_loss, \n",
    "                                          generator_g.trainable_variables)\n",
    "    generator_f_gradients = tape.gradient(total_gen_f_loss, \n",
    "                                        generator_f.trainable_variables)\n",
    "\n",
    "    discriminator_x_gradients = tape.gradient(disc_x_loss, \n",
    "                                            discriminator_x.trainable_variables)\n",
    "    discriminator_y_gradients = tape.gradient(disc_y_loss, \n",
    "                                            discriminator_y.trainable_variables)\n",
    "\n",
    "    # Apply the gradients to the optimizer\n",
    "    generator_g_optimizer.apply_gradients(zip(generator_g_gradients, \n",
    "                                            generator_g.trainable_variables))\n",
    "\n",
    "    generator_f_optimizer.apply_gradients(zip(generator_f_gradients, \n",
    "                                            generator_f.trainable_variables))\n",
    "\n",
    "    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
    "                                                discriminator_x.trainable_variables))\n",
    "\n",
    "    discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
    "                                                discriminator_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MS807LgmXebM"
   },
   "outputs": [],
   "source": [
    "def train_and_checkpoint(ckpt_manager):\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    if ckpt_manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "        n = 0    \n",
    "\n",
    "        for image_x, image_y in tf.data.Dataset.zip((train_WL_ds, train_NBI_ds)):\n",
    "            train_step(image_x, image_y)\n",
    "            if n % 10 == 0:\n",
    "                print ('.', end='')\n",
    "            n += 1\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        # Using a consistent image (sample_horse) so that the progress of the model\n",
    "        # is clearly visible.\n",
    "        generate_images(generator_g, sample_WL)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "\n",
    "        print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "executionInfo": {
     "elapsed": 19477034,
     "status": "ok",
     "timestamp": 1624569857978,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "I8J7EEadLCeq",
    "outputId": "e6e9bacb-8deb-4ffd-b7c7-adc637cfe896"
   },
   "outputs": [],
   "source": [
    "train_and_checkpoint(ckpt_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCIF4Xv9X04s"
   },
   "source": [
    "# **Generate using test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5626,
     "status": "ok",
     "timestamp": 1624569874801,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "0B9kYW0eX7dO",
    "outputId": "3257a721-039b-45e0-b005-63ad5de45a19"
   },
   "outputs": [],
   "source": [
    "# Run the trained model on the test dataset\n",
    "for inp in test_WL_ds.take(5):\n",
    "  generate_images(generator_g, inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6wOa8vB8sBN"
   },
   "source": [
    "# **Predicting over full frames video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76301,
     "status": "ok",
     "timestamp": 1624033968791,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "kH5Y6lUExB67",
    "outputId": "30eeb25a-a1e9-4867-9bef-af613f6f965d"
   },
   "outputs": [],
   "source": [
    "# frames from video path\n",
    "path = '/content/drive/MyDrive/Maestria/Polyps/experiments/data/wl2Nbi/adenomaWL_prueba/real_imgs/'\n",
    "# load dataset white light\n",
    "# here A: white light, B: nbi light\n",
    "adenoma_WL = load_images(path + 'video_1/')\n",
    "print(\"Adenoma WL video_1: \", adenoma_WL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qE4CO_QN9-32"
   },
   "outputs": [],
   "source": [
    "adenoma_WL_array = np.asarray(adenoma_WL)\n",
    "adenoma_WL_ds = tf.data.Dataset.from_tensor_slices(adenoma_WL_array)\n",
    "adenoma_WL_ds = adenoma_WL_ds.map(\n",
    "    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1624034136371,
     "user": {
      "displayName": "Franklin Samuel Sierra Jerez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhOZ4W8-xTi0rwGn3Yugc6h9JX2ob_3eMY8dJb=s64",
      "userId": "07062157042636671418"
     },
     "user_tz": 300
    },
    "id": "hRU93XVI_Hx5",
    "outputId": "8507fa60-8fd5-449b-e765-34f80ca9a25c"
   },
   "outputs": [],
   "source": [
    "# Run the trained model on the test dataset\n",
    "path_solve = '/content/drive/MyDrive/Maestria/Polyps/experiments/data/wl2Nbi/adenomaWL_prueba/fake_imgs/'\n",
    "folder = 'video_1_fake/'\n",
    "path_img_solved = path_solve + folder\n",
    "\n",
    "\n",
    "for count, inp in enumerate(adenoma_WL_ds.take(-1)):\n",
    "  fake = generator_g(inp)\n",
    "  fake = fake[0]* 0.5 + 0.5\n",
    "  #para que PIL Image deje guardar (mult por 255 and change by uint8)\n",
    "  fake = np.array(fake) * 255\n",
    "  fake = fake.astype(np.uint8)\n",
    "  fake_img = Image.fromarray(fake)\n",
    "  name_file = path_img_solved + 'img_' + str(count) + '.png' \n",
    "  fake_img.save(name_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIFey_SrJqzW"
   },
   "source": [
    "**Creating video from fake frames predicted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYF0XGghPaiL"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "img_array = []\n",
    "for filename in glob.glob('/content/drive/MyDrive/Maestria/Polyps/experiments/data/wl2Nbi/adenomaWL_prueba/fake_imgs/video_1_fake/*.png'):\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "out = cv2.VideoWriter('project.avi',cv2.VideoWriter_fourcc(*'DIVX'), 7, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lj1gp3avPomn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPAQPpaalA3H1MyI5B0C0a1",
   "mount_file_id": "1PErs7QQlODdCoyKR28vTNul3lTGovSGc",
   "name": "cycleGan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
