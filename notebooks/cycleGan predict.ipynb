{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.4 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#allows to import generator and discriminator\n",
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#AUTOTUNE = tf.data.AUTOTUNE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in a directory into memory\n",
    "def load_images(path, size=(256,256)):\n",
    "    data_list = list()\n",
    "    #enumerate filenames in directory, assume all are images\n",
    "    for filename in listdir(path):\n",
    "        # load and resize the image\n",
    "        pixels = load_img(path + filename, target_size=size)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        # store\n",
    "        data_list.append(pixels)\n",
    "    return asarray(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, c, month, folder, label):\n",
    "    \n",
    "    pair_path = '../imgs_results/wl2nbi/fake_images_ck4/igho/' + month + '/' + folder + '/pair_images/'\n",
    "    if not os.path.exists(pair_path):\n",
    "        os.makedirs(pair_path)\n",
    "    \n",
    "    wl_path = '../imgs_results/wl2nbi/fake_images_ck4/igho/' + month + '/' + folder + '/realWL/'\n",
    "    if not os.path.exists(wl_path):\n",
    "        os.makedirs(wl_path)\n",
    "    \n",
    "    artif_path = '../imgs_results/wl2nbi/fake_images_ck4/igho/' + month + '/' + folder + '/artifNBI/'\n",
    "    if not os.path.exists(artif_path):\n",
    "        os.makedirs(artif_path)\n",
    "    \n",
    "    \n",
    "    prediction = model(test_input)\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    #saving singles images\n",
    "    \n",
    "    #real WL\n",
    "    name_file = wl_path + label + '_img_' + str(c) + '.png'\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    tf.keras.preprocessing.image.save_img(name_file, display_list[0] * 0.5 + 0.5)\n",
    "    \n",
    "    \n",
    "    #artif NBI\n",
    "    name_file = artif_path + label + '_img_' + str(c) + '.png'\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    tf.keras.preprocessing.image.save_img(name_file, display_list[1] * 0.5 + 0.5)\n",
    "\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "        \n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    name_file = pair_path + label + '_img_' + str(c) + '.png'\n",
    "    plt.savefig(name_file, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data augmentation techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "# scaling the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def random_jitter(image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_train(image):\n",
    "    image = random_jitter(image)\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "def preprocess_image_test(image):\n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import and reuse the Pix2Pix models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing optimizers, generator and discriminators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"../models/rgb/\"\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from ../models/rgb/ckpt-12\n"
     ]
    }
   ],
   "source": [
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(generator_g, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames from video path\n",
    "path = \"../../../../pregrado/data/RGB/WL/adenoma_WL/video_1/\"\n",
    "# load dataset white light\n",
    "# here A: white light, B: nbi light\n",
    "adenoma_WL = load_images(path)\n",
    "print(\"Adenoma WL video_1: \", adenoma_WL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adenoma_WL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-beebc4009af5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madenoma_WL_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madenoma_WL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0madenoma_WL_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madenoma_WL_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m adenoma_WL_ds = adenoma_WL_ds.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n\u001b[1;32m      4\u001b[0m                 BUFFER_SIZE).batch(BATCH_SIZE)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adenoma_WL' is not defined"
     ]
    }
   ],
   "source": [
    "adenoma_WL_array = np.asarray(adenoma_WL)\n",
    "adenoma_WL_ds = tf.data.Dataset.from_tensor_slices(adenoma_WL_array)\n",
    "adenoma_WL_ds = adenoma_WL_ds.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "                BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **testeando**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the trained model on the test dataset\n",
    "for inp in adenoma_WL_ds.take(adenoma_WL.shape[0]):\n",
    "    generate_images(generator_g, inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGHO predicting\n",
    "Nota: septiembre esta en proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2021-09-02-106236', '2021-09-02-106239', '2021-09-02-106262', '2021-09-09-106762', '2021-09-09-106786', '2021-09-11-107014', '2021-09-11-107050']\n"
     ]
    }
   ],
   "source": [
    "month = \"SEPTIEMBRE\"\n",
    "txt_folder = '../imgs_results/wl2nbi/fake_images_ck4/igho/' + month + '/' + 'folders.txt'\n",
    "with open(txt_folder) as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "folders = [cont.split('\\n')[0] for cont in content]\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../imgs_results/wl2nbi/fake_images_ck4/igho/SEPTIEMBRE/2021-09-02-106236/polyps.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-999cf5530d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpathImgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/data/Datasets/Igho/Uncompressed/Videos/\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/Normal/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../imgs_results/wl2nbi/fake_images_ck4/igho/SEPTIEMBRE/2021-09-02-106236/polyps.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "folder = folders[0]\n",
    "label = 'adenoma'\n",
    "#test\n",
    "txt_path = '../imgs_results/wl2nbi/fake_images_ck4/igho/' + month + '/' + folder + '/' + 'polyps.txt'\n",
    "\n",
    "pathImgs = \"/data/Datasets/Igho/Uncompressed/Videos/\"+ month + \"/\" + folder + \"/Normal/\"\n",
    "\n",
    "with open(txt_path) as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "frames = [cont.split('.')[0] for cont in content]\n",
    "\n",
    "data_list = list()\n",
    "size=(256,256)\n",
    "for frame in frames:\n",
    "    to_read = pathImgs + frame + '.png'\n",
    "    pixels = load_img(to_read, target_size=size)\n",
    "    # convert to numpy array\n",
    "    pixels = img_to_array(pixels)\n",
    "    # store\n",
    "    data_list.append(pixels)\n",
    "\n",
    "WL = asarray(data_list)\n",
    "\n",
    "print(\"The folder: {} has a shape of: {}\".format(folder,WL.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WL_array = np.asarray(WL)\n",
    "WL_ds = tf.data.Dataset.from_tensor_slices(WL_array)\n",
    "WL_ds = WL_ds.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "                BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, inp in zip(frames, WL_ds.take(WL.shape[0])):\n",
    "    generate_images(generator_g, inp, index, month, folder, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting over full frames videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatingImages(data, generator, salve_path):\n",
    "    \n",
    "    for count, inp in enumerate(data):\n",
    "        fake = generator(inp)\n",
    "        fake = fake[0]* 0.5 + 0.5\n",
    "        #para que PIL Image deje guardar (mult por 255 and change by uint8)\n",
    "        fake = np.array(fake) * 255\n",
    "        fake = fake.astype(np.uint8)\n",
    "        fake_img = Image.fromarray(fake)\n",
    "        \n",
    "        #checking if directory exist\n",
    "        directory = salve_path.split('/')[:-1]\n",
    "        directory = \"/\".join(directory)\n",
    "        if not os.path.exists(directory):\n",
    "            os.mkdir(directory)\n",
    "        \n",
    "        clase = directory.split('/')[-2:]\n",
    "        clase = \"_\".join(clase)\n",
    "        salve_path = directory + '/' + clase + '_img_' + str(count) + '.png'\n",
    "        fake_img.save(salve_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDataSet(path_origen):\n",
    "    data = load_images(path_origen)\n",
    "    print(\"dimensiones de data: \", data.shape)\n",
    "    data_array = np.asarray(data)\n",
    "    data_ds = tf.data.Dataset.from_tensor_slices(data_array)\n",
    "    data_ds = data_ds.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "                    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    \n",
    "    return data_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames from video path\n",
    "path = '/Users/frank/Documents/Tesis/Polipos/DataSet/PolypDatasetProcesed/WL/'\n",
    "save = '/Users/frank/Documents/maestria/propuesta/experiments/data/wl2nbi/fake_images_ck80/'\n",
    "clases = os.listdir(path)\n",
    "for clase in clases:\n",
    "    print(\"========= clase \", clase, \"=========\")\n",
    "    clase_pth = path + clase + '/'\n",
    "    videos = os.listdir(clase_pth)\n",
    "    for video in videos:\n",
    "        print(\"===\",video, \"====\")\n",
    "        video_pth = clase_pth + video + '/'\n",
    "        print(\"convirtiendo a tf.Dataset...\")\n",
    "        data_ds = toDataSet(video_pth)\n",
    "        imgs = os.listdir(video_pth)\n",
    "        print(\"prediciendo con cycleGan...\")\n",
    "        path_save = save + clase + '/' + video + '/'\n",
    "        generatingImages(data_ds, generator_g, path_save)\n",
    "            \n",
    "\n",
    "print(\"Finalizado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating video from fake frames predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "path = '/Users/frank/Documents/maestria/propuesta/experiments/data/wl2nbi/fake_images_ck80/serrated_WL/video_2/*.png'\n",
    "\n",
    "img_array = []\n",
    "for filename in glob.glob(path):\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "out = cv2.VideoWriter('serV2.avi',cv2.VideoWriter_fourcc(*'DIVX'), 7, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
